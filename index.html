<!DOCTYPE html>
<!-- saved from url=(0034)https://ruizhao26.github.io/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Rui Zhao</title>
<meta content="Rui Zhao" name="Rui Zhao">
<link href="./rzhao_files/style.css" rel="stylesheet" type="text/css">
<script src="./rzhao_files/jquery-1.11.1.min.js" type="text/javascript"></script>  
</head>

<body>
  <div class="menu"> <a href="https://ruizhao26.github.io/index.html">Home</a> 
  <a href="https://ruizhao26.github.io/index.html#news">News</a> 
  <a href="https://ruizhao26.github.io/index.html#bio">Bio</a> 
  <a href="https://ruizhao26.github.io/index.html#education">Education</a>
  <a href="https://ruizhao26.github.io/index.html#publications">Publications</a>
  <a href="https://ruizhao26.github.io/index.html#projects">Projects</a> 
  <a href="https://ruizhao26.github.io/index.html#awards"> Awards/Services</a>   
  <!-- <a href="https://ruizhao26.github.io/index.html#code"> Code/Data</a>  -->
  </div>
  <div class="container">
    <table border="0" class="profile">
      <tbody><tr>
        <!-- <td><img src="./rzhao_files/profile_crop.jpg" width="180" height="200"></td> -->
        <!-- <td><img src="./rzhao_files/profile_v2.png" width="300" height="240"></td> -->
        <!-- <td><img src="./rzhao_files/profile_v3.png" width="280" height=""></td> -->
        <td><img src="./rzhao_files/profile_v4.png" width="280" height=""></td>
        <td style="width: 10px">&nbsp;</td>
        <td valign="top" width="500">
          <span class="name">Rui Zhao (赵睿)</span>
          <p class="information"><br>
          Research Fellow <br>
          <a href="https://www.ntu.edu.sg/computing">College of Computing and Data Science</a> <br>
          <a href="https://www.ntu.edu.sg">Nanyang Technological University</a>.</p>

          <p class="information">No.50 Nanyang Avenue, <br>
          Singapore. <br>
          <!-- Room 2728, Science Building #2, Peking University. -->
          <p class="information"><strong>Email</strong>: ruizhao26</span>@gmail.com</span> &nbsp zhao.rui</span>@ntu.edu.sg</span> &nbsp <span> <s>ruizhao</span>@stu.pku.edu.cn</span></s> </p>
            
          <a href="https://scholar.google.com/citations?user=Ju7_T9cAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp;&nbsp;&nbsp;&nbsp;  <a href="https://www.linkedin.com/in/rui-zhao-247055189/">Linkedin</a> &nbsp;&nbsp;&nbsp;&nbsp;
          <!-- <a href="https://ruizhao26.github.io/files/CV_en.pdf">Curriculum Vitae</a> &nbsp;&nbsp;&nbsp;&nbsp; <a href="https://ruizhao26.github.io/files/CV_cn.pdf">Curriculum Vitae(CN)</a> </p> -->
        </td>
      </tr>
    </tbody></table>

    <a id="news" class="anchor"></a>
    <span class="section">News</span>
    <table border="0" class="news">
    <tr>
      <td>
        <p><strong>[2025.08]</strong> One cooperated paper are accepted by <strong>SCIS</strong>. Congratulations to SpikeCV Team!</p>
        <p><strong>[2025.06]</strong> Two cooperated papers are accepted by <strong>ICCV 2025</strong>. Congratulations to Yuanlin and Jing!</p>
        <p><strong>[2025.05]</strong> I have passed my Ph.D. defense! </p>
        <p><strong>[2025.04]</strong> We are holding the <a href="https://spikecv.github.io/competition.html">1st SpikeCV competition</a>@IJCAI 2025. Come and join us!</p>
        <p><strong>[2024.12]</strong> One cooperated paper is accepted by <strong>TCSVT</strong>. Congratulations to Zhenkun!</p>
        <p><strong>[2024.11]</strong> I obtain the National Scholarship for Ph.D. Students of Peking University.</p>
        <p><strong>[2024.02]</strong> One first-authored paper for spike camera image reconstruction is accepted by <strong>CVPR 2024</strong>.</p>
        <p><strong>[2023.12]</strong> One first-authored paper for spike-based optical flow is accepted by <strong>AAAI 2024</strong>.</p>
        <p><strong>[2023.10]</strong> The website of SpikeCV open-source platform has been released! [<a href="https://spikecv.github.io/index.html">English</a>] [<a href="https://spikecv.github.io/zh/index.html">Chinese</a>]</strong>.</p>
        <p><strong>[2023.10]</strong> One first-authored paper for spike camera image reconstruction is accepted by <strong>TCSVT</strong>.</p>
        <p><strong>[2023.09]</strong> I obtain the Industrial Bank Scholarship.</p>
        <p><strong>[2023.09]</strong> One cooperated paper is accepted by <strong>NeurIPS 2023</strong>. Congratulations to Lujie!</p>
        <p><strong>[2023.01]</strong> One cooperated paper is accepted by <strong>ISCAS 2023</strong>. Congratulations to Yanchen!</p>
        <p><strong>[2022.11]</strong> One cooperated paper is accepted by <strong>AAAI 2023</strong>. Congratulations to Jing!</p>
        <p><strong>[2022.09]</strong> I obtain the UbiQuant Scholarship.</p>
        <p><strong>[2022.09]</strong> One first-authored paper for spike-based optical flow is accepted by <strong>NeurIPS 2022</strong>.</p>
        <p><strong>[2022.06]</strong> I obtain the President Scholarship for Ph.D. Students of Peking University.</p>
        <p><strong>[2022.03]</strong> One jointly first-authored paper for spike-based optical flow is accepted by <strong>CVPR 2022</strong>. Congratulations to Liwen!</p>
      </td>
    </tr>
  </table>


    <a id="bio" class="anchor"></a>
    <span class="section">Breif Bio</span>
    <table border="0" class="bio" width="85%">
    <tr>
    <td width="80%">
      I received the Ph.D. degree in Computer Science from Peking University, China, under the supervision of Prof. <a href="https://scholar.google.com/citations?user=46Rur-YAAAAJ&hl=zh-CN">Ruiqin Xiong</a> in 2025 and the B.E. degree in Communication Engineering from Tianjin University, China in 2020. I am currently a Research Fellow at Nanyang Technological University, Singapore, working with Prof. <a href="https://dr.ntu.edu.sg/entities/person/Lin-Weisi">Weisi Lin</a>.  My research interests include areas of image processing,
      computational photography and computer vision, particularly for topics related to motion estimation and neuromorphic cameras.
    </td>
    </tr>
  </table>


    <a id="education" class="education"></a><span class="section">Education</span>
    <p class="education">
    <b>Peking University</b>. <br>
    2020 - present, Ph.D., &nbsp; Computer Science.       
    </p>
    <p class="education">
      <b>Tianjin University</b>. <br>
      2016 - 2020, &nbsp;&nbsp;&nbsp;   B.Eng., Communication Engineering.       
    </p>
    <p class="education">
      <b>Nankai University</b>. <br>
      2017 - 2020, &nbsp;&nbsp;&nbsp; B.Ec., &nbsp;&thinsp;  Finance. (Double Degree)  
    </p>
      
    <!-- <p>&nbsp;</p> -->


    <!-- Publication session -->
    <a id="publications" class="anchor"></a><span class="section">Publications</a> </span>
    <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px;">
      <tbody>
        
      
      <tr>
        <td>
          <img src="./images/pubpic/spikecv_scis.png" width="200" height="110">
        </td>
        <td>
          [J4] <papertitle><a href="https://www.sciengine.com/SCIS/doi/10.1007/s11432-023-4565-6">
          SpikeCV: Open a Continuous Computer Vision Era</a></papertitle> <br>
          Yajing Zheng, Jiyuan Zhang, <strong>Rui Zhao</strong>, Jianhao Ding, Shiyan Chen, Weijian Wu, Ruiqin Xiong, Zhaofei Yu, and Tiejun Huang <br>
          <em> Science China: Information Sciences </em> (<strong>SCIS</strong>) 2025 <br>
          [<a href="https://www.sciengine.com/cfs/files/pdfs/view/1674-733X/99FBF974168A463AB5C1CE677AC1B3B0-mark.pdf">pdf</a>] 
          [<a href="https://openi.pcl.ac.cn/Cordium/SpikeCV.git">code</a>] 
        </td>
      </tr>

      
      <tr>
        <td>
          <img src="./images/pubpic/iccv2025_sample.png" width="200" height="100">
        </td>
        <td>
          [C13] <papertitle><a href="https://openaccess.thecvf.com/content/ICCV2025/html/Wang_SAMPLE_Semantic_Alignment_through_Temporal-Adaptive_Multimodal_Prompt_Learning_for_Event-Based_ICCV_2025_paper.html">
            SAMPLE: Semantic Alignment through Temporal-Adaptive Multimodal Prompt Learning for Event-Based Open-Vocabulary Action Recognition</a></papertitle> <br>
            Jing Wang, <strong>Rui Zhao</strong>, Ruiqin Xiong, Xingtao Wang, Xiaopeng Fan, and Tiejun Huang <br>
            <em> IEEE/CVF Conference on Computer Vision </em> (<strong>ICCV</strong>) 2025 <br>
            [<a href="https://openaccess.thecvf.com/content/ICCV2025/papers/Wang_SAMPLE_Semantic_Alignment_through_Temporal-Adaptive_Multimodal_Prompt_Learning_for_Event-Based_ICCV_2025_paper.pdf">pdf</a>] 
            [<a href="https://github.com/JingWang-self/SAMPLE">code</a>] 
          </td>
        </tr>
        
        <tr>
          <td>
            <img src="./images/pubpic/iccv2025_isp2hr.png" width="200" height="75">
          </td>
          <td>
            [C12] <papertitle><a href="https://openaccess.thecvf.com/content/ICCV2025/html/Wang_ISP2HRNet_Learning_to_Reconstruct_High_Resolution_Image_from_Irregularly_Sampled_ICCV_2025_paper.html">
              ISP2HRNet: Learning to Reconstruct High Resolution Image from Irregularly Sampled Pixels via Hierarchical Gradient Learning</a></papertitle> <br>
              Yuanlin Wang, Ruiqin Xiong, <strong>Rui Zhao</strong>, Jin Wang, Xiaopeng Fan, and Tiejun Huang <br>
              <em> IEEE/CVF Conference on Computer Vision </em> (<strong>ICCV</strong>) 2025  [<strong>Highlight</strong>]<br> 
              [<a href="https://openaccess.thecvf.com/content/ICCV2025/papers/Wang_ISP2HRNet_Learning_to_Reconstruct_High_Resolution_Image_from_Irregularly_Sampled_ICCV_2025_paper.pdf">pdf</a>] 
        </td>
      </tr>

      <tr>
        <td>
          <img src="./images/pubpic/csvt2024.png" width="200" height="95">
        </td>
        <td>
          [J3] <papertitle><a href="https://ieeexplore.ieee.org/abstract/document/10835763">
            High Dynamic Range Imaging for Dynamic Scenes Based on Multi-Level Spike Camera</a></papertitle> <br>
          Zhenkun Zhu, Ruiqin Xiong, Jing Zhao, <strong>Rui Zhao</strong>, Xiaopeng Fan, Shuyuan Zhu, and Tiejun Huang <br>
          <em> IEEE Transactions on Circuits and Systems for Video Technology </em> (<strong>TCSVT</strong>) 2025 <br>
          [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10835763">pdf</a>] 
          <!-- [<a href="https://github.com/ruizhao26/BSF">code</a>] -->
        </td>
      </tr>

      <tr>
        <td>
          <img src="./images/pubpic/cvpr2024.png" width="200" height="95">
        </td>
        <td>
          [C11] <papertitle><a href="https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Boosting_Spike_Camera_Image_Reconstruction_from_a_Perspective_of_Dealing_CVPR_2024_paper.html">
            Boosting Spike Camera Image Reconstruction from a Perspective of Dealing with Spike Fluctuations</a></papertitle> <br>
          <strong>Rui Zhao</strong>, Ruiqin Xiong, Jing Zhao, Jian Zhang, Xiaopeng Fan, Zhaofei Yu, and Tiejun Huang <br>
          <em> IEEE/CVF Conference on Computer Vision and Pattern Recognition </em> (<strong>CVPR</strong>) 2024 <br>
          [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zhao_Boosting_Spike_Camera_Image_Reconstruction_from_a_Perspective_of_Dealing_CVPR_2024_paper.pdf">pdf</a>] 
          [<a href="https://ruizhao26.github.io/files/BSF_poster_git.pdf">poster</a>]
          [<a href="https://github.com/ruizhao26/BSF">code</a>]
        </td>
      </tr>

      <tr>
        <td>
          <img src="./images/pubpic/aaai2024.png" width="200" height="73">
        </td>
        <td>
          [C10] <papertitle><a href="https://ojs.aaai.org/index.php/AAAI/article/view/28581">
            Optical Flow for Spike Camera with Hierarchical Spatial-Temporal Spike Fusion</a></papertitle> <br>
          <strong>Rui Zhao</strong>, Ruiqin Xiong, Jian Zhang, Xinfeng Zhang, Zhaofei Yu, and Tiejun Huang <br>
          <em> AAAI Conference on Artificial Intelligence </em> (<strong>AAAI</strong>) 2024 <br>
          [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/28581/29130">pdf</a>] 
          [<a href="https://ruizhao26.github.io/files/HiST-SFlow_poster_git.pdf">poster</a>]
          [<a href="https://github.com/ruizhao26/HiST-SFlow">code</a>] 
        </td>
      </tr>

      <tr>
        <td>
          <img src="./images/pubpic/csvt2023.png" width="200" height="107">
        </td>
        <td>
          [J2] <papertitle><a href="https://ieeexplore.ieee.org/abstract/document/10288531">
            Spike Camera Image Reconstruction Using Deep Spiking Neural Networks</a></papertitle> <br>
          <strong>Rui Zhao</strong>, Ruiqin Xiong, Jian Zhang, Zhaofei Yu, Shuyuan Zhu, Lei Ma, and Tiejun Huang <br>
          <em> IEEE Transactions on Circuits and Systems for Video Technology </em> (<strong>TCSVT</strong>) 2024 <br>
          [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10288531">pdf</a>]
          [<a href="https://github.com/ruizhao26/SSIR">code</a>]
        </td>
      </tr>

      <tr>
        <td>
          <img src="./images/pubpic/usflow.png" width="200" height="70">
        </td>
        <td>
          [C9] <papertitle><a href="https://openreview.net/forum?id=7gbjsgcN5p">
            Unsupervised Optical Flow Estimation with Dynamic Timing Representation for Spike Camera</a></papertitle> <br>
          Lujie Xia, Ziluo Ding, <strong>Rui Zhao</strong>, Jiyuan Zhang, Lei Ma, Zhaofei Yu, Tiejun Huang, and Ruiqin Xiong <br>
          <em> Annual Conference on Neural Information Processing Systems </em> (<strong>NeurIPS</strong>) 2023 <br>
          [<a href="https://openreview.net/pdf?id=7gbjsgcN5p">pdf</a>] 
          [<a href="https://github.com/Bosserhead/USFlow">code coming soon</a>] 
          [<a href="https://arxiv.org/abs/2307.06003.pdf">arxiv</a>] 
        </td>
      </tr>

      <tr>
        <td>
          <img src="./images/pubpic/iscas2023.png" width="200" height="70">
        </td>
        <td>
          [C8] <papertitle><a href=https://ieeexplore.ieee.org/document/10182150">
          Optimization-Inspired Deep Network for Image Restoration from Partial Random Samples</a></papertitle> <br>
          Yanchen Dong, <strong>Rui Zhao</strong>, Ruiqin Xiong, Shuyuan Zhu, Xiaopeng Fan, and Tiejun Huang <br>
          <em> IEEE  International Symposium on Circuits and Systems </em> (<strong>ISCAS</strong>) 2023 <br>
          [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10182150">pdf</a>]
        </td>
      </tr>

      <tr>
        <td>
          <img src="./images/pubpic/aaai2023.png" width="200" height="90">
        </td>
        <td>
          [C7] <papertitle><a href="https://ojs.aaai.org/index.php/AAAI/article/view/25468">
            Learning to Super-Resolve Dynamic Scenes for Neuromorphic Spike Camera</a></papertitle> <br>
          Jing Zhao, Ruiqin Xiong, Jian Zhang, <strong>Rui Zhao</strong>, Hangfan Liu, and Tiejun Huang <br>
          <em> AAAI Conference on Artificial Intelligence </em> (<strong>AAAI</strong>) 2023 <br>
          [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/25468">pdf</a>]
        </td>
      </tr>

      <tr>
        <td>
          <img src="./images/pubpic/neurips2022.png" width="200" height="90">
        </td>
        <td>
          [C6] <papertitle><a href="https://openreview.net/forum?id=3vYkhJIty7E">
          Learning Optical Flow From Continuous Spike Streams</a></papertitle> <br>
          <strong>Rui Zhao</strong>, Ruiqin Xiong, Jing Zhao, Zhaofei Yu, Xiaopeng Fan, and Tiejun Huang <br>
          <em> Annual Conference on Neural Information Processing Systems </em> (<strong>NeurIPS</strong>) 2022 <br>
          [<a href="https://openreview.net/pdf?id=3vYkhJIty7E">pdf</a>]
          [<a href="https://neurips.cc/media/PosterPDFs/NeurIPS%202022/55189.png">poster</a>]
          [<a href="https://github.com/ruizhao26/Spike2Flow">code</a>]
        </td>
      </tr>

      <tr>
        <td>
          <img src="./images/pubpic/cvpr2022.png" width="200" height="90">
        </td>
        <!-- <td bgcolor="#e9eaed"> -->
        <td>
          [C5] <papertitle><a href="https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Optical_Flow_Estimation_for_Spiking_Camera_CVPR_2022_paper.html">
          Optical Flow Estimation for Spiking Camera</a></papertitle> <br>
          Liwen Hu#, <strong> Rui Zhao#</strong>, Ziluo Ding, Lei Ma, Boxin Shi, Ruiqin Xiong, and Tiejun Huang. <br>
          (# Equal Contribution) <br>
          <em> IEEE/CVF Conference on Computer Vision and Pattern Recognition </em> (<strong>CVPR</strong>) 2022 <br>
          [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Optical_Flow_Estimation_for_Spiking_Camera_CVPR_2022_paper.pdf">pdf</a>]
          [<a href="https://arxiv.org/abs/2110.03916">arxiv</a>]
          [<a href="https://github.com/Acnext/Optical-Flow-For-Spiking-Camera">code</a>]
        </td>
      </tr>

      <tr>
        <td>
          <img src="./images/pubpic/aaai2022_2.png" width="200" height="150">
        </td>
        <td>
          [C4] <papertitle><a href="https://ojs.aaai.org/index.php/AAAI/article/view/19931">
          Spatio-Temporal Recurrent Networks for Event-Based Optical Flow Estimation</a></papertitle> <br>
          Ziluo Ding, <strong>Rui Zhao</strong>, Jiyuan Zhang, Tianxiao Gao, Ruiqin Xiong, Zhaofei Yu, and Tiejun Huang.<br>
          <em> AAAI Conference on Artificial Intelligence </em> (<strong>AAAI</strong>) 2022 <br>
          [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/19931">pdf</a>]
          [<a href="https://arxiv.org/abs/2109.04871">arxiv</a>]
          [<a href="https://github.com/ruizhao26/STE-FlowNet">code</a>]
        </td>
      </tr>

      <tr>
        <td>
          <img src="./images/pubpic/csvt2022_2.png" width="200" height="80">
        </td>
        <!-- <td bgcolor="#e9eaed"> -->
        <td>
          [J1] <papertitle><a href="https://ieeexplore.ieee.org/document/9648363">
          MRDFlow: Unsupervised Optical Flow Estimation Network With Multi-Scale Recurrent Decoder</a></papertitle> <br>
          <strong>Rui Zhao</strong>, Ruiqin Xiong, Ziluo Ding, Xiaopeng Fan, Jian Zhang, and Tiejun Huang. <br>
          <em> IEEE Transactions on Circuits and Systems for Video Technology </em> (<strong>TCSVT</strong>) 2022 <br>
          [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9648363">pdf</a>]
        </td>
      </tr>

      <tr>
        <td>
          <img src="./images/pubpic/icip2021.png" width="200" height="100">
        </td>
        <td>
          [C3] <papertitle><a href="https://ieeexplore.ieee.org/document/9506149">
            Recover the Residual of Residual: Recurrent Residual Refinement Network for Image Super-Resolution</a></papertitle> <br>
          Tianxiao Gao, Ruiqin Xiong, <strong>Rui Zhao</strong>, Jian Zhang, Shuyuan Zhu, and Tiejun Huang. <br>
          <em> IEEE International Conference on Image Processing </em> (<strong>ICIP</strong>) 2021 <br>
          [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9506149">pdf</a>]
        </td>
      </tr>

      <tr>
        <td>
          <img src="./images/pubpic/vcip2020b.png" width="200" height="120">
        </td>
        <td>
          [C2] <papertitle><a href="https://ieeexplore.ieee.org/document/9301840">
            Motion Estimation for Spike Camera Data Sequence via Spike Interval Analysis</a></papertitle> <br>
          Jing Zhao, Ruiqin Xiong, <strong>Rui Zhao</strong>, Jin Wang, Siwei Ma, and Tiejun Huang. <br>
          <em> IEEE International Conference on Visual Communications and Image Processing </em> (<strong>VCIP</strong>) 2020 <br>
          [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9301840">pdf</a>]
        </td>
      </tr>

      <tr>
        <td>
          <img src="./images/pubpic/vcip2020a.png" width="200" height="100">
        </td>
        <!-- <td bgcolor="#e9eaed"> -->
        <td>
          [C1] <papertitle><a href="https://ieeexplore.ieee.org/document/9301771">
            Optical Flow Estimation Between Images of Different Resolutions via Variational Method</a></papertitle> <br>
          <strong>Rui Zhao</strong>, Ruiqin Xiong, Shuyuan Zhu, Bing Zeng, Tiejun Huang, and Wen Gao. <br>
          <em> IEEE International Conference on Visual Communications and Image Processing </em> (<strong>VCIP</strong>) 2020 <br>
          [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9301771">pdf</a>]
        </td>
      </tr>


    </tbody></table>
    <!-- <p>&nbsp;</p> -->
    
    <!-- Publication session -->
    <a id="preprints" class="anchor"></a><span class="section">Preprints</a> </span>
    <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px;">
      <tbody>
 
        <tr>
          <td>
            <img src="./images/pubpic/mowe.png" width="200" height="100">
          </td>
          <td>
            [P1] <papertitle><a href="https://arxiv.org/abs/2303.13739">
              WM-MoE: Weather-aware Multi-scale Mixture-of-Experts for Blind Adverse Weather Removal</a></papertitle> <br>
            Yulin Luo, <strong>Rui Zhao</strong>, Xiaobao Wei, Jinwei Chen, Yijie Lu, Shenghao Xie, Tianyu Wang, Ruiqin Xiong, Ming Lu, and Shanghang Zhang <br>
            Preprint - arxiv 2023 <br>
            [<a href="https://arxiv.org/pdf/2303.13739.pdf">pdf</a>]
          </td>
        </tr>

        <tr>
          <td>
            <img src="./images/pubpic/spikestereo.png" width="200" height="100">
          </td>
          <td>
            [P2] <papertitle><a href="https://arxiv.org/abs/2505.19487v1">
              SpikeStereoNet: A Brain-Inspired Framework for Stereo Depth Estimation from Spike Streams</a></papertitle> <br>
            Zhuoheng Gao, Yihao Li, Jiyao Zhang, <strong>Rui Zhao</strong>, Tong Wu, Hao Tang, Zhaofei Yu, Hao Dong, Guozhang Chen, Tiejun Huang <br>
            Preprint - arxiv 2025 <br>
            [<a href="https://arxiv.org/pdf/2505.19487v1">pdf</a>]
          </td>
        </tr>
 
    </tbody></table>
    <!-- <p>&nbsp;</p> -->


   <!-- Publication session -->
   <a id="projects" class="anchor"></a><span class="section">Projects</a> </span>
   <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px;">
     <tbody>

     <tr>
      <td>
      &nbsp; &nbsp; &nbsp; &nbsp;
      </td>
       <td>
         <img src="./images/pubpic/spikecv_logo_new.png" width="100" height="120">
       </td>
       <td>
        &nbsp; &nbsp; &nbsp; &nbsp;
       </td>

       <td>
         <papertitle><a href="https://git.openi.org.cn/Cordium/SpikeCV">
         SpikeCV: An Open-Source Framework for Spike Vision</a></papertitle> <br>
         Yajing Zheng, Jiyuan Zhang, <strong>Rui Zhao</strong>, Jianhao Ding, Shiyan Chen, and et al. <br>
         <!-- <em> Annual Conference on Neural Information Processing Systems </em> (<strong>NeurIPS</strong>) 2022 <br> -->
         [<a href="https://spikecv.github.io">Website</a>]
         [<a href="https://spikecv.github.io/zh/index.html">Website(CN)</a>]
         [<a href="https://git.openi.org.cn/Cordium/SpikeCV">Openi-Git(CN)</a>]
         [<a href="https://github.com/Zyj061/SpikeCV">Github</a>]
         [<a href="https://arxiv.org/pdf/2303.11684.pdf">pdf</a>]
       </td>
     </tr>

   </tbody></table>
   <!-- <p>&nbsp;</p> -->
     

              
    <!-- Awards session -->
    <a id="awards"></a><span class="section">Awards</span>

  <ul>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          National Scholarship for Ph.D. Students of Peking University (4%), 2024</font></b></font></font></b></p>
    </li>
    
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          President Scholarship for Ph.D. Students of Peking University (2%), 2022</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          President Scholarship for Ph.D. Students of Peking University (2%), 2021</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          President Scholarship for Ph.D. Students of Peking University (2%), 2020</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          Industrial Bank Scholarship of Peking University, 2023</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          UbiQuant Scholarship of Peking University, 2022</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          Merit Student of Peking University (15%), 2022, 2023, 2024</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          Outstanding Developer Award of OpenI Community, 2023</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          Outstanding Student Model Honorable Mention Scholarship of Tianjin University (0.05%), 2019</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          National Scholarship for Bachelor Students of Tianjin University (2%), 2019</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          National Scholarship for Bachelor Students of Tianjin University (2%), 2018</font></b></font></font></b></p>
    </li>

  </ul>

  </font>

  <!-- <p>&nbsp;</p> -->
  
  </ul>
    <a id="services"></a><span class="section">Academic Services</span>

  <ul>
    <strong>Reviewer of Journals:</strong>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
         IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) </font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
         IEEE Transactions on Image Processing (TIP) </font></b></font></font></b></p>
    </li>
    
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) </font></b></font></font></b></p>
    </li>
   
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          IEEE Transactions on Multimedia (TMM) </font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          IEEE Transactions on Intelligent Vehicles (TIV) </font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          Image and Video Computing (IVC) </font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
           APSIPA Transactions on Signal and Information Processing </font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
           Intelligence Computing </font></b></font></font></b></p>
    </li>
    
    <p></p>
    <strong>Reviewer of Conferences:</strong>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2022 - 2026</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          IEEE/CVF International Conference on Computer Vision (ICCV) 2023, 2025</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          Annual Conference on Neural Information Processing Systems (NeurIPS) 2024 - 2025</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          International Conference on Machine Learning (ICML) 2025</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          Internaltional Conference on Learning Representations (ICLR) 2025 - 2026</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          European Conference on Computer Vision (ECCV) 2022, 2024</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          AAAI Conference on Artificial Intelligence (AAAI) 2023 - 2026</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          International Joint Conference on Artificial Intelligence (IJCAI) 2025</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          ACM International Conference on Multimedia (ACM MM) 2025</font></b></font></font></b></p>
    </li>

    <!-- <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          International Conference on Artificial Intelligence and Statistics (AISTATS) 2025</font></b></font></font></b></p>
    </li> -->

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          IEEE International Conference on Robotics and Automation (ICRA) 2024</font></b></font></font></b></p>
    </li>
    
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          ACM Multimedia Asia (MM Asia) 2025</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          Asian Conference on Computer VIsion (ACCV) 2024</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          IEEE International Conference on Image Processing (ICIP) 2022 - 2025</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          IEEE Winter Conference on Applications of Computer Vision (WACV) 2026</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          IEEE International Conference on Visual Communication and Image Processing (VCIP) 2025</font></b></font></font></b></p>
    </li>

  </ul>

  </font>
  </ul>

  <p><font color="#000000" face='Lato' size="2">&copy 2025 Rui Zhao. Thanks to <a href="http://people.csail.mit.edu/celiu"><font color="#000080">Dr. Ce Liu</font></a> and 
  <a href="https://deqings.github.io/index.html"><font color="#000080">Dr. Deqing Sun</font></a> for the template. </font></p>

  <!-- </div> -->
  <!-- <script>
    var thumbnails = document.getElementsByClassName("PaperThumbnail");
    var i;
    for (i = 0; i < thumbnails.length; i++) {
      thumbnails[i].width = "120"
    }
  </script>   -->

</body></html>
